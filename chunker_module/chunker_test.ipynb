{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a018925d",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93d93277",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import traceback\n",
    "from langchain_openai import ChatOpenAI\n",
    "from agentic_chunker import AgenticChunker\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "import os\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b716a73b",
   "metadata": {},
   "source": [
    "# Tools inializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2afead50",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "chunker = AgenticChunker(api_key = openai_key , model= llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8af692cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/home/youssef/github/Modular_RAG/PDFs/1H2025_Earnings_Release.pdf\"\n",
    "loader = PyMuPDFLoader(\n",
    "    file_path , \n",
    "    mode=\"page\"\n",
    ")\n",
    "\n",
    "doc = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5510e50",
   "metadata": {},
   "source": [
    "# Chunking technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "08d152d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-- Step 1: Processing Document with Agentic Chunker --\n",
      "\n",
      "ERROR: None of the common processing methods were found. The method name is highly specific to your library version.\n",
      "\n",
      "-- Step 2: Agentic Chunking Complete. Retrieving Results --\n",
      "\n",
      "Could not find a standard result retrieval method ('chunks' or 'get_chunks').\n"
     ]
    }
   ],
   "source": [
    "# Assuming the chunker processes the entire list of Document objects at once.\n",
    "\n",
    "print(\"\\n-- Step 1: Processing Document with Agentic Chunker --\\n\")\n",
    "\n",
    "# Pass the entire list of Document objects (doc) to a method like 'process_documents'\n",
    "# You may need to change 'process_documents' to 'run' or 'process' if this fails.\n",
    "try:\n",
    "    chunker.process_documents(doc)\n",
    "    print(\"Document processing initiated using 'process_documents'.\")\n",
    "except AttributeError:\n",
    "    # If the method is called 'process'\n",
    "    try:\n",
    "        chunker.process(doc)\n",
    "        print(\"Document processing initiated using 'process'.\")\n",
    "    except AttributeError:\n",
    "        # If the method is called 'run'\n",
    "        try:\n",
    "            chunker.run(doc)\n",
    "            print(\"Document processing initiated using 'run'.\")\n",
    "        except AttributeError:\n",
    "            print(\"ERROR: None of the common processing methods were found. The method name is highly specific to your library version.\")\n",
    "            \n",
    "print(\"\\n-- Step 2: Agentic Chunking Complete. Retrieving Results --\\n\")\n",
    "\n",
    "# Retrieve the results using the common retrieval patterns\n",
    "if hasattr(chunker, 'chunks'):\n",
    "    hierarchal_chunks = chunker.chunks\n",
    "    print(f\"Successfully generated {len(hierarchal_chunks)} chunks.\")\n",
    "    \n",
    "    if hierarchal_chunks:\n",
    "        print(\"\\n--- Example of the First Chunk ---\")\n",
    "        first_chunk_key = next(iter(hierarchal_chunks))\n",
    "        print(hierarchal_chunks[first_chunk_key])\n",
    "else:\n",
    "    try:\n",
    "        # Try a common retrieval method\n",
    "        hierarchal_chunks = chunker.get_chunks()\n",
    "        print(f\"Successfully retrieved {len(hierarchal_chunks)} chunks using get_chunks().\")\n",
    "    except AttributeError:\n",
    "        print(\"Could not find a standard result retrieval method ('chunks' or 'get_chunks').\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1a47092b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-- Step 1: Initiating Agentic Chunking --\n",
      "\n",
      "An error occurred during chunking: AgenticChunker.agentic_chunking() missing 1 required positional argument: 'seperator'\n",
      "Please ensure your environment variables (like OpenAI API Key) are correctly set, as this is an LLM-powered process.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n-- Step 1: Initiating Agentic Chunking --\\n\")\n",
    "\n",
    "# The correct method is 'agentic_chunking', which takes the list of documents (doc) \n",
    "# and returns the new list of hierarchically chunked documents.\n",
    "try:\n",
    "    # The 'agentic_chunking' method runs the LLM-powered process\n",
    "    hierarchal_chunks = chunker.agentic_chunking(doc)\n",
    "    \n",
    "    print(f\"Successfully generated {len(hierarchal_chunks)} chunks.\")\n",
    "\n",
    "    if hierarchal_chunks:\n",
    "        print(\"\\n--- Example of the First Chunk ---\")\n",
    "        # Print the page_content and metadata of the first chunk\n",
    "        print(f\"Content:\\n{hierarchal_chunks[0].page_content[:500]}...\")\n",
    "        print(f\"\\nMetadata: {hierarchal_chunks[0].metadata}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during chunking: {e}\")\n",
    "    print(\"Please ensure your environment variables (like OpenAI API Key) are correctly set, as this is an LLM-powered process.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de3a1a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e24e3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
